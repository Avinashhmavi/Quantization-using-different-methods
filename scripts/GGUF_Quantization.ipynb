{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMi8imkcoLxP",
        "outputId": "bdb42b5f-27d2-457d-84db-89bdb3d370d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XibQ-BFVqwvo",
        "outputId": "f63fd627-18e0-4b8a-84b3-39e5366bc0ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet])\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.4.26)\n",
            "Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf-xet\n",
            "Successfully installed hf-xet-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub[hf_xet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUS_rSE2okxN",
        "outputId": "78c3fa20-aeb0-43ea-e226-0d3ebe7a90c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 50596, done.\u001b[K\n",
            "remote: Counting objects: 100% (386/386), done.\u001b[K\n",
            "remote: Compressing objects: 100% (267/267), done.\u001b[K\n",
            "remote: Total 50596 (delta 269), reused 125 (delta 119), pack-reused 50210 (from 4)\u001b[K\n",
            "Receiving objects: 100% (50596/50596), 111.20 MiB | 37.91 MiB/s, done.\n",
            "Resolving deltas: 100% (36435/36435), done.\n",
            "/content/llama.cpp\n",
            "/content/llama.cpp\n",
            "/content/llama.cpp/build\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\") \n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")  \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/llama.cpp/build\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
            "[  4%] Built target ggml-base\n",
            "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
            "[ 10%] Built target ggml-cpu\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
            "[ 11%] Built target ggml\n",
            "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32m\u001b[1mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
            "[ 21%] Built target llama\n",
            "[ 21%] \u001b[34m\u001b[1mGenerating build details from Git\u001b[0m\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\") \n",
            "[ 21%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
            "[ 21%] Built target build_info\n",
            "[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 26%] Built target common\n",
            "[ 27%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n",
            "[ 27%] Built target test-tokenizer-0\n",
            "[ 27%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-sampling\u001b[0m\n",
            "[ 28%] Built target test-sampling\n",
            "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n",
            "[ 29%] Built target test-grammar-parser\n",
            "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n",
            "[ 30%] Built target test-grammar-integration\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n",
            "[ 31%] Built target test-llama-grammar\n",
            "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat\u001b[0m\n",
            "[ 32%] Built target test-chat\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n",
            "[ 34%] Built target test-json-schema-to-grammar\n",
            "[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-stats\u001b[0m\n",
            "[ 35%] Built target test-quantize-stats\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gbnf-validator\u001b[0m\n",
            "[ 35%] Built target test-gbnf-validator\n",
            "[ 36%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n",
            "[ 36%] Built target test-tokenizer-1-bpe\n",
            "[ 37%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n",
            "[ 37%] Built target test-tokenizer-1-spm\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-log\u001b[0m\n",
            "[ 38%] Built target test-log\n",
            "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-template\u001b[0m\n",
            "[ 40%] Built target test-chat-template\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n",
            "[ 41%] Built target test-arg-parser\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gguf\u001b[0m\n",
            "[ 43%] Built target test-gguf\n",
            "[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n",
            "[ 45%] Built target test-backend-ops\n",
            "[ 46%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n",
            "[ 47%] Built target test-model-load-cancel\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-autorelease\u001b[0m\n",
            "[ 48%] Built target test-autorelease\n",
            "[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-barrier\u001b[0m\n",
            "[ 49%] Built target test-barrier\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n",
            "[ 50%] Built target test-quantize-fns\n",
            "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n",
            "[ 52%] Built target test-quantize-perf\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-rope\u001b[0m\n",
            "[ 53%] Built target test-rope\n",
            "[ 54%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n",
            "[ 55%] Built target mtmd\n",
            "[ 55%] \u001b[32mBuilding C object tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-mtmd-c-api\u001b[0m\n",
            "[ 56%] Built target test-mtmd-c-api\n",
            "[ 56%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking C executable ../bin/test-c\u001b[0m\n",
            "[ 57%] Built target test-c\n",
            "[ 57%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched\u001b[0m\n",
            "[ 58%] Built target llama-batched\n",
            "[ 59%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n",
            "[ 59%] Built target llama-embedding\n",
            "[ 60%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n",
            "[ 60%] Built target llama-eval-callback\n",
            "[ 61%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n",
            "[ 61%] Built target sha256\n",
            "[ 62%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n",
            "[ 62%] Built target xxhash\n",
            "[ 62%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n",
            "[ 62%] Built target sha1\n",
            "[ 62%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n",
            "[ 62%] Built target llama-gguf-hash\n",
            "[ 62%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n",
            "[ 63%] Built target llama-gguf\n",
            "[ 64%] \u001b[32mBuilding CXX object examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gritlm\u001b[0m\n",
            "[ 64%] Built target llama-gritlm\n",
            "[ 64%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n",
            "[ 65%] Built target llama-lookahead\n",
            "[ 65%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n",
            "[ 66%] Built target llama-lookup\n",
            "[ 66%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n",
            "[ 67%] Built target llama-lookup-create\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n",
            "[ 67%] Built target llama-lookup-merge\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n",
            "[ 68%] Built target llama-lookup-stats\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n",
            "[ 69%] Built target llama-parallel\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n",
            "[ 70%] Built target llama-passkey\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n",
            "[ 70%] Built target llama-retrieval\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n",
            "[ 71%] Built target llama-save-load-state\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple\u001b[0m\n",
            "[ 72%] Built target llama-simple\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n",
            "[ 73%] Built target llama-simple-chat\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n",
            "[ 74%] Built target llama-speculative\n",
            "[ 75%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n",
            "[ 75%] Built target llama-speculative-simple\n",
            "[ 75%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n",
            "[ 76%] Built target llama-gen-docs\n",
            "[ 77%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n",
            "[ 77%] Built target llama-convert-llama2c-to-ggml\n",
            "[ 77%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n",
            "[ 78%] Built target llama-vdot\n",
            "[ 78%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n",
            "[ 79%] Built target llama-q8dot\n",
            "[ 79%] \u001b[32mBuilding CXX object tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n",
            "[ 80%] Built target llama-batched-bench\n",
            "[ 81%] \u001b[32mBuilding CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
            "[ 81%] Built target llama-gguf-split\n",
            "[ 82%] \u001b[32mBuilding CXX object tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n",
            "[ 82%] Built target llama-imatrix\n",
            "[ 82%] \u001b[32mBuilding CXX object tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-bench\u001b[0m\n",
            "[ 83%] Built target llama-bench\n",
            "[ 83%] \u001b[32mBuilding CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
            "[ 83%] Built target llama-cli\n",
            "[ 83%] \u001b[32mBuilding CXX object tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n",
            "[ 84%] Built target llama-perplexity\n",
            "[ 84%] \u001b[32mBuilding CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
            "[ 85%] Built target llama-quantize\n",
            "[ 86%] \u001b[34m\u001b[1mGenerating loading.html.hpp\u001b[0m\n",
            "[ 86%] \u001b[34m\u001b[1mGenerating index.html.gz.hpp\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object tools/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-server\u001b[0m\n",
            "[ 86%] Built target llama-server\n",
            "[ 87%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-run\u001b[0m\n",
            "[ 88%] Built target llama-run\n",
            "[ 88%] \u001b[32mBuilding CXX object tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n",
            "[ 89%] Built target llama-tokenize\n",
            "[ 89%] \u001b[32mBuilding CXX object tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tts\u001b[0m\n",
            "[ 90%] Built target llama-tts\n",
            "[ 90%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llava.dir/llava.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llava.dir/clip.cpp.o\u001b[0m\n",
            "[ 91%] Built target llava\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX static library libllava_static.a\u001b[0m\n",
            "[ 91%] Built target llava_static\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libllava_shared.so\u001b[0m\n",
            "[ 91%] Built target llava_shared\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX static library libmtmd_static.a\u001b[0m\n",
            "[ 92%] Built target mtmd_static\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libmtmd_shared.so\u001b[0m\n",
            "[ 92%] Built target mtmd_shared\n",
            "[ 93%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n",
            "[ 93%] Built target llama-llava-cli\n",
            "[ 93%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gemma3-cli\u001b[0m\n",
            "[ 94%] Built target llama-gemma3-cli\n",
            "[ 95%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n",
            "[ 95%] Built target llama-minicpmv-cli\n",
            "[ 95%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n",
            "[ 96%] Built target llama-qwen2vl-cli\n",
            "[ 97%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n",
            "[ 97%] Built target llama-mtmd-cli\n",
            "[ 97%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-clip-quantize-cli\u001b[0m\n",
            "[ 98%] Built target llama-llava-clip-quantize-cli\n",
            "[ 99%] \u001b[32mBuilding CXX object tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n",
            "[ 99%] Built target llama-cvector-generator\n",
            "[ 99%] \u001b[32mBuilding CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n",
            "[100%] Built target llama-export-lora\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "%cd llama.cpp\n",
        "%cd /content/llama.cpp\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!cmake --build . --config Release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFDQw2fQrEu6",
        "outputId": "a1b8ac2a-1819-45c0-d35f-4d32243805ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mCMake Warning at CMakeLists.txt:108 (message):\n",
            "  LLAMA_CUDA is deprecated and will be removed in the future.\n",
            "\n",
            "  Use GGML_CUDA instead\n",
            "\n",
            "Call Stack (most recent call first):\n",
            "  CMakeLists.txt:114 (llama_option_depr)\n",
            "\n",
            "\u001b[0m\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Could not find nvcc, please set CUDAToolkit_ROOT.\n",
            "\u001b[31mCMake Error at ggml/src/ggml-cuda/CMakeLists.txt:183 (message):\n",
            "  CUDA Toolkit not found\n",
            "\n",
            "\u001b[0m\n",
            "-- Configuring incomplete, errors occurred!\n",
            "See also \"/content/llama.cpp/build/CMakeFiles/CMakeOutput.log\".\n"
          ]
        }
      ],
      "source": [
        "!cmake .. -DLLAMA_CUDA=ON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhwnSXBuowyT",
        "outputId": "981e0b39-65ef-4494-c544-ba445523cf5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: HF_TOKEN=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\n"
          ]
        }
      ],
      "source": [
        "%env HF_TOKEN="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "6e9f1a8e9d0048f3bec067fe6067af4d",
            "7dc801f58afe4669a6f9c60ca7037da7",
            "35dd1077352b48e980d68373d21f65ef",
            "9d1d7c2a79c14640b65531c171cf7a2a",
            "40fea5febf7e466685857b518ae4ddb0",
            "984d0843086c4b36b7068d2295034270",
            "5595587df8ab4d05bc63b1df0677edee",
            "34ef91567f6346d0a25b92c173b044c0",
            "f6e106db74004973b579417e534f6e21",
            "92a01625c8b344dba7f9d44b05f2d41e",
            "35f3de19ab624159a20bce7f26fedc81",
            "70dc1728c5f848589293a4472d2da816",
            "14daca75c0a942cc9c1df34d23b85e86",
            "44877fed34894a24a80ab9d668ef9eca",
            "b6081c16aa9f4b55a2a980f227cacc4f",
            "b83d6036bc5149c7bea1e05ab83ef131",
            "3af0a2bf71704a988f3243fb0fe3b694",
            "97a579816dea442a87c430aa23c41fc0",
            "8fe3e217cf744c84813cd8645aa54a3c",
            "cead4d62491049c891c267ef6114e4d2",
            "ca53116e515c438aa02f3956013ba6b0",
            "959024b45725452f985006309daed2e5",
            "df2ac014533e4fca882f921b169dcfbd",
            "984efa45c7714a2db210db89585fd1e1",
            "930890b210ed417185c2fd863fac9e85",
            "e79e0e6567cf451a9e8a4f6e23724b65",
            "5e44390b0da84f67b3cf1cd8f882955a",
            "a918fdb1dc4347be856c03472e96a4f5",
            "7e32d63b9564453896e06fbb8b198254",
            "f12147f3793c43378e4e6f245a044324",
            "2e79e1b8e0a645e78fa973df6ff21491",
            "eecfffa67e2744c0aa6ce8eb20e6a0eb",
            "759c7247bc8240e6a597d777c68b54b7",
            "c6c7f7b8267e4a7ab11d66a971174417",
            "6a978672aad74a2e93c183b07168adf3",
            "9dcb904cd7d241108108f2f4cc762a96",
            "650832b9db204d1bab17c9df40ab961c",
            "d85b13868abb481082b595e0e09572ca",
            "3fef41c87bc84a26970002c429486ff3",
            "0a7dd1d15f174a79a228593fe58e2dc5",
            "dc074332a4dd4a4f956f8ab7c645a0f3",
            "09070e8aebf84ab3aa50bf4b0726442e",
            "98a9dc01cc8e43d991c325082c76391c",
            "a405a4cd6a124ad7af9793d35102632b",
            "9d5ac9f1d0564d748c642ead2a3b2705",
            "5537f32185c3420b872eeff97853221d",
            "8f5236569e104ce48ca583440452fcc8",
            "ff0133dbf492465ab0c534fcaf9353d2",
            "27d7252ed35441e4b3c6aa7590ff9d47",
            "c507d113d60c4571b78a36d17dbd3b42",
            "b31007465924447bb41f152625747858",
            "901e4164912a4b53a4dd69e3e7cc59ca",
            "54251695621f440f886d3a33c5229816",
            "e90117b1e4e749c0a961ecab7cd03e0f",
            "20acb95e461146e28080ff4d76488d0a",
            "ece6f2fe53c74970aa1435d5e69a15ae",
            "b3b5340facc14d5695cabbd1953118be",
            "71c824d89d4d467a82bdb8b015c9fd03",
            "c6166a35e6a04cb986abb7cf8fcd3df9",
            "2ab71cd3d501461c984e64b4aad8262c",
            "82c2b436040d411db70775dfa6c02fab",
            "2695f150f8cc4074aa4ee4daf929d1ac",
            "7b348ae3228841278ac27ee801f098b6",
            "97b5a3ec66364bb1b6661ffa77084cc5",
            "d834d37c7639410e9e151a7f35898902",
            "e0b96852618f4485b13db91a3fa65c0b"
          ]
        },
        "id": "3kW2rDOMpFpA",
        "outputId": "c48d4b1b-9439-4c17-b4e8-73ca0dcb2ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model unsloth/Llama-3.2-1B to ./llama-3.2-1b...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e9f1a8e9d0048f3bec067fe6067af4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70dc1728c5f848589293a4472d2da816",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/935 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df2ac014533e4fca882f921b169dcfbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c7f7b8267e4a7ab11d66a971174417",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d5ac9f1d0564d748c642ead2a3b2705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ece6f2fe53c74970aa1435d5e69a15ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving tokenizer to ./llama-3.2-1b...\n",
            "Converting model to GGUF format...\n",
            "Quantizing model to Q4_K_M...\n",
            "Quantized model saved to ./llama-3.2-1b-gguf/ggml-model-Q4_K_M.gguf\n",
            "Cleaning up temporary model directory ./llama-3.2-1b...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "from huggingface_hub import snapshot_download\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define paths and model ID\n",
        "model_id = \"unsloth/Llama-3.2-1B\"\n",
        "model_dir = \"./llama-3.2-1b\"\n",
        "gguf_dir = \"./llama-3.2-1b-gguf\"\n",
        "gguf_model_path = os.path.join(gguf_dir, \"ggml-model-f16.gguf\")\n",
        "quantized_model_path = os.path.join(gguf_dir, \"ggml-model-Q4_K_M.gguf\")\n",
        "llama_cpp_dir = \"/content/llama.cpp\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "os.makedirs(gguf_dir, exist_ok=True)\n",
        "\n",
        "def run_command(command, error_message):\n",
        "    result = subprocess.run(command, capture_output=True, text=True, shell=True)\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"{error_message}: {result.stderr}\")\n",
        "    return result\n",
        "\n",
        "try:\n",
        "    # Step 0: Set up llama.cpp\n",
        "    if not os.path.exists(llama_cpp_dir):\n",
        "        print(\"Setting up llama.cpp...\")\n",
        "        # Install dependencies (for Ubuntu/Colab-like environments)\n",
        "        run_command(\n",
        "            \"apt-get update && apt-get install -y git cmake build-essential\",\n",
        "            \"Failed to install dependencies\"\n",
        "        )\n",
        "        # Clone llama.cpp\n",
        "        run_command(\n",
        "            f\"git clone https://github.com/ggerganov/llama.cpp {llama_cpp_dir}\",\n",
        "            \"Failed to clone llama.cpp\"\n",
        "        )\n",
        "        # Build llama.cpp\n",
        "        os.makedirs(os.path.join(llama_cpp_dir, \"build\"), exist_ok=True)\n",
        "        os.chdir(os.path.join(llama_cpp_dir, \"build\"))\n",
        "        run_command(\n",
        "            \"cmake .. && make -j$(nproc)\",\n",
        "            \"Failed to compile llama.cpp\"\n",
        "        )\n",
        "        os.chdir(\"/content\")  # Return to working directory\n",
        "\n",
        "    # Step 1: Download model from Hugging Face\n",
        "    print(f\"Downloading model {model_id} to {model_dir}...\")\n",
        "    snapshot_download(\n",
        "        repo_id=model_id,\n",
        "        local_dir=model_dir,\n",
        "        token=os.environ.get(\"HF_TOKEN\")  # Or replace with token=\"your_token\"\n",
        "    )\n",
        "\n",
        "    # Step 2: Save tokenizer\n",
        "    print(f\"Saving tokenizer to {model_dir}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ.get(\"HF_TOKEN\"))\n",
        "    tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "    # Step 3: Convert to GGUF\n",
        "    print(\"Converting model to GGUF format...\")\n",
        "    convert_script = os.path.join(llama_cpp_dir, \"convert_hf_to_gguf.py\")\n",
        "    result = subprocess.run(\n",
        "        [\"python\", convert_script, model_dir, \"--outfile\", gguf_model_path, \"--outtype\", \"f16\"],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"GGUF conversion failed: {result.stderr}\")\n",
        "    if not os.path.exists(gguf_model_path):\n",
        "        raise FileNotFoundError(\"GGUF conversion failed: GGUF model not found.\")\n",
        "\n",
        "    # Step 4: Quantize to Q4_K_M\n",
        "    print(\"Quantizing model to Q4_K_M...\")\n",
        "    quantize_bin = os.path.join(llama_cpp_dir, \"build/bin/llama-quantize\")  # Updated path\n",
        "    if not os.path.exists(quantize_bin):\n",
        "        raise FileNotFoundError(f\"llama-quantize binary not found at {quantize_bin}. Please ensure llama.cpp was compiled.\")\n",
        "    result = subprocess.run(\n",
        "        [quantize_bin, gguf_model_path, quantized_model_path, \"Q4_K_M\"],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Quantization failed: {result.stderr}\")\n",
        "\n",
        "    # Verify quantized model\n",
        "    if os.path.exists(quantized_model_path):\n",
        "        print(f\"Quantized model saved to {quantized_model_path}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Quantization failed: Quantized model not found.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "finally:\n",
        "    # Clean up\n",
        "    if os.path.exists(model_dir):\n",
        "        print(f\"Cleaning up temporary model directory {model_dir}...\")\n",
        "        shutil.rmtree(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuqhdFup1gcO",
        "outputId": "41a69eea-c09b-4e64-f82d-7a23728453b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install psutil torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp2hYUo8sxPL",
        "outputId": "9a6bfe43-f8c3-4e58-fbf5-e2e92fbcd752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking GPU compatibility with bfloat16...\n",
            "No NVIDIA GPU detected or nvidia-smi not installed.\n",
            "Quantized model saved to ./llama-3.2-1b-gguf/ggml-model-Q4_K_M.gguf\n",
            "Quantized model saved to ./llama-3.2-1b-gguf/ggml-model-Q8_0.gguf\n",
            "\n",
            "Testing models...\n",
            "\n",
            "Running inference on Original FP16 with prompt: What is the capital of France?\n",
            "Output: What is the capital of France? A. Washington, D.C. B. Montpelier, Vermont C. Baton Rouge, Louisiana D. Paris, France\n",
            "What is the capital of France? A. Washington, D.C. B. Montpelier, Vermont C. Baton Rouge, Louisiana D. Paris, France\n",
            "What is the capital of France? A. Washington, D.C. B. Montpelier, Vermont C. Baton Rouge, Louisiana D. Paris, France\n",
            "The capital of France is Paris, France\n",
            "\n",
            "\n",
            "Inference Time: 109.96 seconds\n",
            "Memory Usage: Baseline 1566.64 MB, Peak 1566.64 MB\n",
            "\n",
            "Running inference on Original FP16 with prompt: Explain the theory of relativity in simple terms.\n",
            "Output: Explain the theory of relativity in simple terms. The theory of relativity is the theory that Albert Einstein came up with. It was his answer to the question of what speed is actually possible. Einstein’s theory of relativity tells us that the speed of light is the speed limit. He did not say that you couldn’t go faster than the speed of light. The speed of light is not an absolute speed. It is a relative speed. That means that the speed of light is relative to your speed. To put it simply, you can go\n",
            "\n",
            "\n",
            "Inference Time: 117.84 seconds\n",
            "Memory Usage: Baseline 1566.64 MB, Peak 1566.64 MB\n",
            "\n",
            "Running inference on Original FP16 with prompt: Write a short poem about the stars.\n",
            "Output: Write a short poem about the stars. It should be no more than 8 lines long and should be in the form of a sonnet. Your sonnet should have 14 lines and 2 stanzas. You should make sure that your poem has a clear thesis statement. The poem should have a rhyming pattern. The rhyming pattern should be ABABCCD. The poem should be about something that is important to you. The poem should be about the stars and how they are important to you. You should\n",
            "\n",
            "\n",
            "Inference Time: 108.10 seconds\n",
            "Memory Usage: Baseline 1566.64 MB, Peak 1566.90 MB\n",
            "\n",
            "Running inference on Quantized Q4_K_M with prompt: What is the capital of France?\n",
            "Output: What is the capital of France? How France is divided up? What is the capital of France?\n",
            "What is the capital of France? How France is divided up? What is the capital of France?\n",
            "France is made up of 27 regions and the capital of France is Paris. The country is divided into 101 departments. Each department is made up of 20 communes. The country is very big and has a lot of people in it. There are 67 languages spoken in the country.\n",
            "Q: What is the capital of\n",
            "\n",
            "\n",
            "Inference Time: 34.91 seconds\n",
            "Memory Usage: Baseline 1566.90 MB, Peak 1566.90 MB\n",
            "\n",
            "Running inference on Quantized Q4_K_M with prompt: Explain the theory of relativity in simple terms.\n",
            "Output: Explain the theory of relativity in simple terms. Discuss the two effects of the theory.\n",
            "A. The first effect is that all objects appear to move at the same speed relative to the observer. This means that all objects appear to be at rest to the observer, and this is known as the principle of relativity. B. The second effect is that the speed of light is the same for all observers. This means that all observers, including the one standing still, see the same objects as travelling at the same speed relative to them, and this\n",
            "\n",
            "\n",
            "Inference Time: 35.27 seconds\n",
            "Memory Usage: Baseline 1566.90 MB, Peak 1566.90 MB\n",
            "\n",
            "Running inference on Quantized Q4_K_M with prompt: Write a short poem about the stars.\n",
            "Output: Write a short poem about the stars. Try to create a poem that has a rhythm and rhyme.\n",
            "Write a short poem about a time you have felt so alone that it hurt. Try to create a poem that has a rhythm and rhyme. [end of text]\n",
            "\n",
            "\n",
            "\n",
            "Inference Time: 15.01 seconds\n",
            "Memory Usage: Baseline 1566.90 MB, Peak 1566.90 MB\n",
            "\n",
            "Running inference on Quantized Q8_0 with prompt: What is the capital of France?\n",
            "Output: What is the capital of France? \n",
            "What is the largest city in France? \n",
            "What is the largest county in France? \n",
            "What is the largest state in France? \n",
            "What is the smallest county in France? \n",
            "What is the smallest state in France? \n",
            "What is the oldest county in France? \n",
            "What is the oldest state in France? \n",
            "What is the second most popular city in France? \n",
            "What is the second oldest county in France? \n",
            "What is the second oldest state in France? \n",
            "What is the second smallest\n",
            "\n",
            "\n",
            "Inference Time: 81.94 seconds\n",
            "Memory Usage: Baseline 1566.90 MB, Peak 1566.90 MB\n",
            "\n",
            "Running inference on Quantized Q8_0 with prompt: Explain the theory of relativity in simple terms.\n",
            "Output: Explain the theory of relativity in simple terms. What is the relationship between the speed of light and the speed of a body?\n",
            "What is the relationship between the speed of light and the speed of a body?\n",
            "The speed of light is defined as the rate at which electromagnetic waves propagate. It is a constant speed of 299,792,458 m/s. It is the fastest speed known to man. This speed is so fast that it is impossible to travel at this speed and still be at rest.\n",
            "How does the speed of light relate to the\n",
            "\n",
            "\n",
            "Inference Time: 72.04 seconds\n",
            "Memory Usage: Baseline 1566.90 MB, Peak 1566.90 MB\n",
            "\n",
            "Running inference on Quantized Q8_0 with prompt: Write a short poem about the stars.\n",
            "Output: Write a short poem about the stars. Then draw an illustration of your poem. Use a color to illustrate your poem.\n",
            "Write a short poem about the stars. Then draw an illustration of your poem. Use a color to illustrate your poem.\n",
            "Write a short poem about the stars. Then draw an illustration of your poem. Use a color to illustrate your poem. [end of text]\n",
            "\n",
            "\n",
            "\n",
            "Inference Time: 54.51 seconds\n",
            "Memory Usage: Baseline 1566.90 MB, Peak 1566.90 MB\n",
            "Cleaning up temporary model directory ./llama-3.2-1b...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import time\n",
        "import psutil\n",
        "from huggingface_hub import snapshot_download\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Define paths and model ID\n",
        "model_id = \"unsloth/Llama-3.2-1B\"\n",
        "model_dir = \"./llama-3.2-1b\"\n",
        "gguf_dir = \"./llama-3.2-1b-gguf\"\n",
        "gguf_model_path = os.path.join(gguf_dir, \"ggml-model-f16.gguf\")\n",
        "quantized_model_path = os.path.join(gguf_dir, \"ggml-model-Q4_K_M.gguf\")\n",
        "llama_cpp_dir = \"/content/llama.cpp\"\n",
        "\n",
        "# Define prompts for testing\n",
        "test_prompts = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"Explain the theory of relativity in simple terms.\",\n",
        "    \"Write a short poem about the stars.\"\n",
        "]\n",
        "\n",
        "# Define quantization configurations\n",
        "quantization_configs = [\n",
        "    \"Q4_K_M\",  # Default quantization\n",
        "    \"Q8_0\"     # Additional quantization for testing\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "os.makedirs(gguf_dir, exist_ok=True)\n",
        "\n",
        "def run_command(command, error_message):\n",
        "    result = subprocess.run(command, capture_output=True, text=True, shell=True)\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"{error_message}: {result.stderr}\")\n",
        "    return result\n",
        "\n",
        "def check_gpu_bfloat16_support():\n",
        "    print(\"Checking GPU compatibility with bfloat16...\")\n",
        "    try:\n",
        "        # Check if NVIDIA GPU is available\n",
        "        result = subprocess.run(\"nvidia-smi\", shell=True, capture_output=True, text=True)\n",
        "        if result.returncode != 0:\n",
        "            print(\"No NVIDIA GPU detected or nvidia-smi not installed.\")\n",
        "            return False\n",
        "\n",
        "        # Check for bfloat16 support (requires CUDA and specific GPU architecture, e.g., Ampere or later)\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda\")\n",
        "            # bfloat16 is supported on GPUs with compute capability >= 8.0 (e.g., A100, RTX 3000 series)\n",
        "            compute_capability = torch.cuda.get_device_capability(device)\n",
        "            if compute_capability[0] >= 8:\n",
        "                print(f\"GPU supports bfloat16 (Compute Capability: {compute_capability[0]}.{compute_capability[1]})\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"GPU does not support bfloat16 (Compute Capability: {compute_capability[0]}.{compute_capability[1]})\")\n",
        "                return False\n",
        "        else:\n",
        "            print(\"CUDA not available. GPU bfloat16 support cannot be checked.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking GPU bfloat16 support: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def measure_memory():\n",
        "    \"\"\"Measure current memory usage in MB.\"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    mem_info = process.memory_info()\n",
        "    return mem_info.rss / 1024 / 1024  # Convert to MB\n",
        "\n",
        "def run_inference(model_path, prompt, model_name):\n",
        "    \"\"\"Run inference using llama.cpp and measure performance.\"\"\"\n",
        "    print(f\"\\nRunning inference on {model_name} with prompt: {prompt}\")\n",
        "    start_time = time.time()\n",
        "    baseline_memory = measure_memory()\n",
        "\n",
        "    llama_cli = os.path.join(llama_cpp_dir, \"build/bin/llama-cli\")\n",
        "    if not os.path.exists(llama_cli):\n",
        "        raise FileNotFoundError(f\"llama-cli binary not found at {llama_cli}. Please compile llama.cpp.\")\n",
        "\n",
        "    # Run inference\n",
        "    result = subprocess.run(\n",
        "        [llama_cli, \"-m\", model_path, \"-p\", prompt, \"--n-predict\", \"100\"],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Inference failed for {model_name}: {result.stderr}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    inference_time = end_time - start_time\n",
        "    peak_memory = measure_memory()\n",
        "\n",
        "    print(f\"Output: {result.stdout}\")\n",
        "    print(f\"Inference Time: {inference_time:.2f} seconds\")\n",
        "    print(f\"Memory Usage: Baseline {baseline_memory:.2f} MB, Peak {peak_memory:.2f} MB\")\n",
        "    return result.stdout, inference_time, peak_memory\n",
        "\n",
        "try:\n",
        "    # Step 0: Check GPU bfloat16 support\n",
        "    has_bfloat16_support = check_gpu_bfloat16_support()\n",
        "\n",
        "    # Step 1: Download model from Hugging Face (if not already done)\n",
        "    if not os.path.exists(gguf_model_path):\n",
        "        print(f\"Downloading model {model_id} to {model_dir}...\")\n",
        "        snapshot_download(\n",
        "            repo_id=model_id,\n",
        "            local_dir=model_dir,\n",
        "            token=os.environ.get(\"HF_TOKEN\")\n",
        "        )\n",
        "\n",
        "        # Step 2: Save tokenizer\n",
        "        print(f\"Saving tokenizer to {model_dir}...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ.get(\"HF_TOKEN\"))\n",
        "        tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "        # Step 3: Convert to GGUF\n",
        "        print(\"Converting model to GGUF format...\")\n",
        "        convert_script = os.path.join(llama_cpp_dir, \"convert_hf_to_gguf.py\")\n",
        "        result = subprocess.run(\n",
        "            [\"python\", convert_script, model_dir, \"--outfile\", gguf_model_path, \"--outtype\", \"f16\"],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        if result.returncode != 0:\n",
        "            raise RuntimeError(f\"GGUF conversion failed: {result.stderr}\")\n",
        "        if not os.path.exists(gguf_model_path):\n",
        "            raise FileNotFoundError(\"GGUF conversion failed: GGUF model not found.\")\n",
        "\n",
        "    # Step 4: Quantize model for each configuration\n",
        "    quantize_bin = os.path.join(llama_cpp_dir, \"build/bin/llama-quantize\")\n",
        "    if not os.path.exists(quantize_bin):\n",
        "        raise FileNotFoundError(f\"llama-quantize binary not found at {quantize_bin}. Please compile llama.cpp.\")\n",
        "\n",
        "    for quant_type in quantization_configs:\n",
        "        quantized_model_path = os.path.join(gguf_dir, f\"ggml-model-{quant_type}.gguf\")\n",
        "        if not os.path.exists(quantized_model_path):\n",
        "            print(f\"Quantizing model to {quant_type}...\")\n",
        "            result = subprocess.run(\n",
        "                [quantize_bin, gguf_model_path, quantized_model_path, quant_type],\n",
        "                capture_output=True, text=True\n",
        "            )\n",
        "            if result.returncode != 0:\n",
        "                raise RuntimeError(f\"Quantization failed for {quant_type}: {result.stderr}\")\n",
        "            if not os.path.exists(quantized_model_path):\n",
        "                raise FileNotFoundError(f\"Quantization failed: {quantized_model_path} not found.\")\n",
        "        print(f\"Quantized model saved to {quantized_model_path}\")\n",
        "\n",
        "    # Step 5: Test original (FP16) and quantized models\n",
        "    print(\"\\nTesting models...\")\n",
        "    models_to_test = [\n",
        "        (gguf_model_path, \"Original FP16\"),\n",
        "        (os.path.join(gguf_dir, \"ggml-model-Q4_K_M.gguf\"), \"Quantized Q4_K_M\"),\n",
        "        (os.path.join(gguf_dir, \"ggml-model-Q8_0.gguf\"), \"Quantized Q8_0\")\n",
        "    ]\n",
        "\n",
        "    for model_path, model_name in models_to_test:\n",
        "        if os.path.exists(model_path):\n",
        "            for prompt in test_prompts:\n",
        "                output, inference_time, peak_memory = run_inference(model_path, prompt, model_name)\n",
        "        else:\n",
        "            print(f\"Skipping {model_name}: Model file {model_path} not found.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "finally:\n",
        "    # Clean up\n",
        "    if os.path.exists(model_dir):\n",
        "        print(f\"Cleaning up temporary model directory {model_dir}...\")\n",
        "        shutil.rmtree(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYNuXJnz1Lvi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09070e8aebf84ab3aa50bf4b0726442e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a7dd1d15f174a79a228593fe58e2dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14daca75c0a942cc9c1df34d23b85e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af0a2bf71704a988f3243fb0fe3b694",
            "placeholder": "​",
            "style": "IPY_MODEL_97a579816dea442a87c430aa23c41fc0",
            "value": "config.json: 100%"
          }
        },
        "20acb95e461146e28080ff4d76488d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2695f150f8cc4074aa4ee4daf929d1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27d7252ed35441e4b3c6aa7590ff9d47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab71cd3d501461c984e64b4aad8262c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e79e1b8e0a645e78fa973df6ff21491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34ef91567f6346d0a25b92c173b044c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35dd1077352b48e980d68373d21f65ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ef91567f6346d0a25b92c173b044c0",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6e106db74004973b579417e534f6e21",
            "value": 8
          }
        },
        "35f3de19ab624159a20bce7f26fedc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af0a2bf71704a988f3243fb0fe3b694": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fef41c87bc84a26970002c429486ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40fea5febf7e466685857b518ae4ddb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44877fed34894a24a80ab9d668ef9eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe3e217cf744c84813cd8645aa54a3c",
            "max": 935,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cead4d62491049c891c267ef6114e4d2",
            "value": 935
          }
        },
        "54251695621f440f886d3a33c5229816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5537f32185c3420b872eeff97853221d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c507d113d60c4571b78a36d17dbd3b42",
            "placeholder": "​",
            "style": "IPY_MODEL_b31007465924447bb41f152625747858",
            "value": "model.safetensors: 100%"
          }
        },
        "5595587df8ab4d05bc63b1df0677edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e44390b0da84f67b3cf1cd8f882955a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650832b9db204d1bab17c9df40ab961c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a9dc01cc8e43d991c325082c76391c",
            "placeholder": "​",
            "style": "IPY_MODEL_a405a4cd6a124ad7af9793d35102632b",
            "value": " 1.57k/1.57k [00:00&lt;00:00, 187kB/s]"
          }
        },
        "6a978672aad74a2e93c183b07168adf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fef41c87bc84a26970002c429486ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_0a7dd1d15f174a79a228593fe58e2dc5",
            "value": ".gitattributes: 100%"
          }
        },
        "6e9f1a8e9d0048f3bec067fe6067af4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dc801f58afe4669a6f9c60ca7037da7",
              "IPY_MODEL_35dd1077352b48e980d68373d21f65ef",
              "IPY_MODEL_9d1d7c2a79c14640b65531c171cf7a2a"
            ],
            "layout": "IPY_MODEL_40fea5febf7e466685857b518ae4ddb0"
          }
        },
        "70dc1728c5f848589293a4472d2da816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14daca75c0a942cc9c1df34d23b85e86",
              "IPY_MODEL_44877fed34894a24a80ab9d668ef9eca",
              "IPY_MODEL_b6081c16aa9f4b55a2a980f227cacc4f"
            ],
            "layout": "IPY_MODEL_b83d6036bc5149c7bea1e05ab83ef131"
          }
        },
        "71c824d89d4d467a82bdb8b015c9fd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b348ae3228841278ac27ee801f098b6",
            "max": 5717,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b5a3ec66364bb1b6661ffa77084cc5",
            "value": 5717
          }
        },
        "759c7247bc8240e6a597d777c68b54b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b348ae3228841278ac27ee801f098b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc801f58afe4669a6f9c60ca7037da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984d0843086c4b36b7068d2295034270",
            "placeholder": "​",
            "style": "IPY_MODEL_5595587df8ab4d05bc63b1df0677edee",
            "value": "Fetching 8 files: 100%"
          }
        },
        "7e32d63b9564453896e06fbb8b198254": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82c2b436040d411db70775dfa6c02fab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5236569e104ce48ca583440452fcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_901e4164912a4b53a4dd69e3e7cc59ca",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54251695621f440f886d3a33c5229816",
            "value": 2471645608
          }
        },
        "8fe3e217cf744c84813cd8645aa54a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901e4164912a4b53a4dd69e3e7cc59ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a01625c8b344dba7f9d44b05f2d41e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930890b210ed417185c2fd863fac9e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12147f3793c43378e4e6f245a044324",
            "max": 230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e79e1b8e0a645e78fa973df6ff21491",
            "value": 230
          }
        },
        "959024b45725452f985006309daed2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a579816dea442a87c430aa23c41fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97b5a3ec66364bb1b6661ffa77084cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "984d0843086c4b36b7068d2295034270": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984efa45c7714a2db210db89585fd1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a918fdb1dc4347be856c03472e96a4f5",
            "placeholder": "​",
            "style": "IPY_MODEL_7e32d63b9564453896e06fbb8b198254",
            "value": "generation_config.json: 100%"
          }
        },
        "98a9dc01cc8e43d991c325082c76391c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1d7c2a79c14640b65531c171cf7a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a01625c8b344dba7f9d44b05f2d41e",
            "placeholder": "​",
            "style": "IPY_MODEL_35f3de19ab624159a20bce7f26fedc81",
            "value": " 8/8 [00:03&lt;00:00,  1.20it/s]"
          }
        },
        "9d5ac9f1d0564d748c642ead2a3b2705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5537f32185c3420b872eeff97853221d",
              "IPY_MODEL_8f5236569e104ce48ca583440452fcc8",
              "IPY_MODEL_ff0133dbf492465ab0c534fcaf9353d2"
            ],
            "layout": "IPY_MODEL_27d7252ed35441e4b3c6aa7590ff9d47"
          }
        },
        "9dcb904cd7d241108108f2f4cc762a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc074332a4dd4a4f956f8ab7c645a0f3",
            "max": 1570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09070e8aebf84ab3aa50bf4b0726442e",
            "value": 1570
          }
        },
        "a405a4cd6a124ad7af9793d35102632b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a918fdb1dc4347be856c03472e96a4f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b31007465924447bb41f152625747858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3b5340facc14d5695cabbd1953118be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c2b436040d411db70775dfa6c02fab",
            "placeholder": "​",
            "style": "IPY_MODEL_2695f150f8cc4074aa4ee4daf929d1ac",
            "value": "README.md: 100%"
          }
        },
        "b6081c16aa9f4b55a2a980f227cacc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca53116e515c438aa02f3956013ba6b0",
            "placeholder": "​",
            "style": "IPY_MODEL_959024b45725452f985006309daed2e5",
            "value": " 935/935 [00:00&lt;00:00, 120kB/s]"
          }
        },
        "b83d6036bc5149c7bea1e05ab83ef131": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c507d113d60c4571b78a36d17dbd3b42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6166a35e6a04cb986abb7cf8fcd3df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d834d37c7639410e9e151a7f35898902",
            "placeholder": "​",
            "style": "IPY_MODEL_e0b96852618f4485b13db91a3fa65c0b",
            "value": " 5.72k/5.72k [00:00&lt;00:00, 824kB/s]"
          }
        },
        "c6c7f7b8267e4a7ab11d66a971174417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a978672aad74a2e93c183b07168adf3",
              "IPY_MODEL_9dcb904cd7d241108108f2f4cc762a96",
              "IPY_MODEL_650832b9db204d1bab17c9df40ab961c"
            ],
            "layout": "IPY_MODEL_d85b13868abb481082b595e0e09572ca"
          }
        },
        "ca53116e515c438aa02f3956013ba6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cead4d62491049c891c267ef6114e4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d834d37c7639410e9e151a7f35898902": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85b13868abb481082b595e0e09572ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc074332a4dd4a4f956f8ab7c645a0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2ac014533e4fca882f921b169dcfbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_984efa45c7714a2db210db89585fd1e1",
              "IPY_MODEL_930890b210ed417185c2fd863fac9e85",
              "IPY_MODEL_e79e0e6567cf451a9e8a4f6e23724b65"
            ],
            "layout": "IPY_MODEL_5e44390b0da84f67b3cf1cd8f882955a"
          }
        },
        "e0b96852618f4485b13db91a3fa65c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e79e0e6567cf451a9e8a4f6e23724b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eecfffa67e2744c0aa6ce8eb20e6a0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_759c7247bc8240e6a597d777c68b54b7",
            "value": " 230/230 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "e90117b1e4e749c0a961ecab7cd03e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece6f2fe53c74970aa1435d5e69a15ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b5340facc14d5695cabbd1953118be",
              "IPY_MODEL_71c824d89d4d467a82bdb8b015c9fd03",
              "IPY_MODEL_c6166a35e6a04cb986abb7cf8fcd3df9"
            ],
            "layout": "IPY_MODEL_2ab71cd3d501461c984e64b4aad8262c"
          }
        },
        "eecfffa67e2744c0aa6ce8eb20e6a0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12147f3793c43378e4e6f245a044324": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e106db74004973b579417e534f6e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff0133dbf492465ab0c534fcaf9353d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90117b1e4e749c0a961ecab7cd03e0f",
            "placeholder": "​",
            "style": "IPY_MODEL_20acb95e461146e28080ff4d76488d0a",
            "value": " 2.47G/2.47G [00:03&lt;00:00, 1.80GB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
